{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4870234c-1915-4797-953d-1443ab7bfb55",
   "metadata": {},
   "source": [
    "### Pre-defined Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128e0133-7d02-407b-8dbb-0475283774bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def test_compute_metrics(label, pred):\n",
    "    MAE = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        if pred[i][-1] == '.':\n",
    "            pred[i] = pred[i][:-1]\n",
    "        \n",
    "        MAE.append(1 - mean_absolute_error([float(label[i])], [float(pred[i])]))\n",
    "    \n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478d07b6-2288-46a6-b9d5-45536894c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\",\n",
    "                     index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4334c46-0cea-433f-b64a-214d23526eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>OCEAN</th>\n",
       "      <th>speaker</th>\n",
       "      <th>file</th>\n",
       "      <th>scenario</th>\n",
       "      <th>num_discourse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 우선 그래프를 봤을 때 연령대가 나오는데 일단 중년층이랑 고등학생과 이제 대학...</td>\n",
       "      <td>[0.9791666666666667, 0.9791666666666667, 0.833...</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>BP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>특히 여기 지역 특산물 판매 부스도 있어가지고 좀 지역 특산물 이 부스랑 좀 연계해...</td>\n",
       "      <td>[0.9791666666666667, 0.9791666666666667, 0.833...</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>BP</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>맥심 골드 그거를 제일 좋아하시니까 나이 드신 연령대가</td>\n",
       "      <td>[0.9791666666666667, 0.9791666666666667, 0.833...</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>BP</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네 탕후루 가격을 어떻게 할 건지?</td>\n",
       "      <td>[0.9791666666666667, 0.9791666666666667, 0.833...</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>BP</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이게 종목이 딱 정해져 빠르게 해결책을 찾은 것 같아요 그럼 저희가 우리 부스를 알...</td>\n",
       "      <td>[0.9791666666666667, 0.9791666666666667, 0.833...</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>BP</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>그럼 노라조는 한 오백이면 되지 않을까 오 노래를</td>\n",
       "      <td>[0.5208333333333334, 0.6875, 0.791666666666666...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>GS</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>근데 그 목소리가 팽수여야 되잖아요 더 싸게 부를 수 있는 사람이 있을까</td>\n",
       "      <td>[0.5208333333333334, 0.6875, 0.791666666666666...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>GS</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>뜬금없는 걸로 하면 설민석님이 근데 생각보다 저는 한혜진 님이 제일 인기를 못 끄실...</td>\n",
       "      <td>[0.5208333333333334, 0.6875, 0.791666666666666...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>GS</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>설은석 님이랑 비슷해 그쪽이어가지고 뷰티</td>\n",
       "      <td>[0.5208333333333334, 0.6875, 0.791666666666666...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>GS</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>10분에 70만 원이요 거의 뭐</td>\n",
       "      <td>[0.5208333333333334, 0.6875, 0.791666666666666...</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>GS</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transcription  \\\n",
       "0    저는 우선 그래프를 봤을 때 연령대가 나오는데 일단 중년층이랑 고등학생과 이제 대학...   \n",
       "1    특히 여기 지역 특산물 판매 부스도 있어가지고 좀 지역 특산물 이 부스랑 좀 연계해...   \n",
       "2                       맥심 골드 그거를 제일 좋아하시니까 나이 드신 연령대가   \n",
       "3                                  네 탕후루 가격을 어떻게 할 건지?   \n",
       "4    이게 종목이 딱 정해져 빠르게 해결책을 찾은 것 같아요 그럼 저희가 우리 부스를 알...   \n",
       "..                                                 ...   \n",
       "626                        그럼 노라조는 한 오백이면 되지 않을까 오 노래를   \n",
       "627           근데 그 목소리가 팽수여야 되잖아요 더 싸게 부를 수 있는 사람이 있을까   \n",
       "628  뜬금없는 걸로 하면 설민석님이 근데 생각보다 저는 한혜진 님이 제일 인기를 못 끄실...   \n",
       "629                             설은석 님이랑 비슷해 그쪽이어가지고 뷰티   \n",
       "630                                  10분에 70만 원이요 거의 뭐   \n",
       "\n",
       "                                                 OCEAN  speaker  file  \\\n",
       "0    [0.9791666666666667, 0.9791666666666667, 0.833...        9    36   \n",
       "1    [0.9791666666666667, 0.9791666666666667, 0.833...        9    36   \n",
       "2    [0.9791666666666667, 0.9791666666666667, 0.833...        9    36   \n",
       "3    [0.9791666666666667, 0.9791666666666667, 0.833...        9    36   \n",
       "4    [0.9791666666666667, 0.9791666666666667, 0.833...        9    36   \n",
       "..                                                 ...      ...   ...   \n",
       "626  [0.5208333333333334, 0.6875, 0.791666666666666...        8    44   \n",
       "627  [0.5208333333333334, 0.6875, 0.791666666666666...        8    44   \n",
       "628  [0.5208333333333334, 0.6875, 0.791666666666666...        8    44   \n",
       "629  [0.5208333333333334, 0.6875, 0.791666666666666...        8    44   \n",
       "630  [0.5208333333333334, 0.6875, 0.791666666666666...        8    44   \n",
       "\n",
       "    scenario  num_discourse  \n",
       "0         BP              1  \n",
       "1         BP              7  \n",
       "2         BP             13  \n",
       "3         BP             15  \n",
       "4         BP             19  \n",
       "..       ...            ...  \n",
       "626       GS             41  \n",
       "627       GS             46  \n",
       "628       GS             48  \n",
       "629       GS             50  \n",
       "630       GS             56  \n",
       "\n",
       "[631 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41f717-db2d-492a-9bc5-91be3f15bc84",
   "metadata": {},
   "source": [
    "### Zero-shot LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8925a77e-ddf2-4659-9321-9a20032b65b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [31:16<00:00,  2.97s/it]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import logging\n",
    "logging.disable(logging.INFO) \n",
    "logging.disable(logging.WARNING) \n",
    "\n",
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\")  # 데이터 불러오기 (First Impression V2 데이터의 Test set 불러오기)\n",
    "\n",
    "model_id = 'Bllossom/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M'  # 모델 이름\n",
    "GGUF = \"llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf\" # GGUF 경로\n",
    "model = Llama(\n",
    "    model_path='/data/visi2/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf',\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=-1,       \n",
    "    verbose=False, \n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "zero_shot2 = '당신은 문장에 대해 OCEAN 성격 요소 각각에 대한 점수를 알려주는 전문가 입니다. \\n\\\n",
    "OCEAN 성격 요소는 다음에 대한 사항을 확인합니다. O(Openness), C(Conscientiousness), E(Extraversion), A(Agreeableness), N(Neuroticism) \\n\\\n",
    "주어진 문장을 읽고, 문장에서 나타나는 OCEAN 성격 요소들을 분석하여 각각의 요소에 0에서 1 사이의 점수를 매기세요. \\n\\\n",
    "점수는 문장에서 해당 요소가 얼마나 잘 드러나는지를 기반으로 하며, 0에 가까울수록 전혀 드러나지 않음을, 1에 가까울수록 매우 강하게 드러남을 의미합니다. \\n\\\n",
    "다음의 예시와 같이 출력 값으로 주어진 문장에 대한 OCEAN 성격 요소 5가지를 각각의 점수로 나타내어야합니다. [O: 0.6722, C: 0.8322, E: 0.4860, A: 0.5298, N: 0.9323] \\n\\\n",
    "'\n",
    "\n",
    "generation_kwargs = {  \n",
    "    \"max_tokens\" : 512, \n",
    "    \"temperature\" : 0.6,\n",
    "    \"top_p\" :0.9,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])  # 결과를 저장할 데이터프레임\n",
    "\n",
    "for content in tqdm(FI_test['transcription'].to_list()):\n",
    "    user = content\n",
    "    inputs = tokenizer.encode(zero_shot2 + '문장: \"' + user + '\",\\n 결과- [O: ', return_tensors='pt').to(\"cuda\")  # 입력 데이터 토크나이징\n",
    "    raw_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['  # 토크나이징 전 텍스트\n",
    "    outputs = model(raw_inputs, **generation_kwargs)\n",
    "\n",
    "    out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "    tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "    result_df = pd.concat([result_df, tmp_df])\n",
    "\n",
    "# KULLM, KoSOLAR (SOLAR-10.7B) : 약 21GB GPU 메모리 소모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9098423-f612-4d57-96cc-f27f7f8402a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Inference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d7e3e6-317e-4883-83ce-d3283ec140bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "p = re.compile('0[.]\\d*')\n",
    "\n",
    "for content in result_df['Inference'].to_list():\n",
    "    tmp = p.findall(content)\n",
    "    score.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3560e6b1-794a-4a43-914c-fd9522332d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.5437', '0.8471', '0.3965', '0.5822', '0.7586'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.7000', '0.8500', '0.3500', '0.4000', '0.3000'],\n",
       " ['0.5', '0.8', '0.6', '0.4', '0.9'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.2'],\n",
       " ['0.7', '0.8', '0.5', '0.6', '0.9'],\n",
       " ['0.0', '0.0', '0.0'],\n",
       " ['0.6486', '0.8478', '0.5151', '0.5619', '0.9215'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.9'],\n",
       " ['0.5', '0.6', '0.4', '0.5', '0.5'],\n",
       " ['0.5', '0.8', '0.6', '0.4', '0.7'],\n",
       " ['0.5426', '0.8457', '0.5159', '0.5431', '0.7793'],\n",
       " ['0.5', '0.6', '0.8', '0.4', '0.7'],\n",
       " ['0.8502', '0.9101', '0.7007', '0.8901', '0.3231'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8', '0.7', '0.5', '0.6', '0.4'],\n",
       " ['0.8', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.1092', '0.5821', '0.6706', '0.7299'],\n",
       " ['0.6869', '0.8478', '0.5137', '0.5486', '0.9565'],\n",
       " ['0.4000', '0.5000', '0.7000', '0.1000', '0.9000'],\n",
       " ['0.0', '0.0', '0.0', '0.8', '0.0'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.5'],\n",
       " ['0.5', '0.8', '0.2', '0.6', '0.7'],\n",
       " ['0.6869', '0.6107', '0.6062', '0.8525', '0.5607'],\n",
       " ['0.5', '0.8', '0.6', '0.6', '0.4'],\n",
       " ['0.8', '0.3', '0.5', '0.2', '0.4'],\n",
       " ['0.6869', '0.8478', '0.4991', '0.5532', '0.9566'],\n",
       " ['0.8', '0.6', '0.5', '0.7', '0.9'],\n",
       " ['0.6489', '0.8476', '0.5152', '0.5774', '0.9031'],\n",
       " ['0.8', '0.4', '0.2', '0.7', '0.9'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.87', '0.45', '0.91', '0.60', '0.34'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.6489', '0.8536', '0.5132', '0.5439', '0.9721'],\n",
       " ['0.8', '0.3', '0.4', '0.5', '0.6'],\n",
       " ['0.7582', '0.8478', '0.5547', '0.6069', '0.9685'],\n",
       " ['0.8', '0.9', '0.6', '0.5', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.3', '0.7', '0.6', '0.4', '0.5'],\n",
       " ['0.3', '0.5', '0.2', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.86', '0.55', '0.78', '0.82', '0.62'],\n",
       " ['0.5', '0.4', '0.3', '0.2', '0.1'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.7', '0.4', '0.6', '0.3'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.4'],\n",
       " ['0.5', '0.5', '0.8', '0.6', '0.4'],\n",
       " ['0.7', '0.5', '0.6', '0.4'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7'],\n",
       " ['0.5', '0.6', '0.4', '0.3', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.87', '0.45', '0.24', '0.38', '0.92'],\n",
       " ['0.6861', '0.7395', '0.7795', '0.6429', '0.6066'],\n",
       " ['0.8522', '0.1111', '0.7777', '0.4444', '0.5555'],\n",
       " ['0.8', '0.4', '0.9', '0.6', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6709', '0.6861', '0.8431', '0.9355'],\n",
       " ['0.7000', '0.8500', '0.4000', '0.5000', '0.9000'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.00', '0.00', '0.00', '0.00'],\n",
       " ['0.5', '0.6', '0.4', '0.5', '0.3'],\n",
       " ['0.5', '0.8', '0.2', '0.6', '0.9'],\n",
       " ['0.6869', '0.8478', '0.5036', '0.5504', '0.9562'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7', '0.8', '0.5', '0.4', '0.6', '0.2'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.8', '0.4', '0.6', '0.7', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.8', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.4', '0.5', '0.6', '0.7'],\n",
       " ['0.0', '0.0', '0.5', '0.0', '0.0', '0.0', '0.5', '0.0'],\n",
       " ['0.8', '0.2', '0.5', '0.1', '0.4'],\n",
       " ['0.8', '0.7', '0.6', '0.5', '0.4'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.2',\n",
       "  '0.6',\n",
       "  '0.4',\n",
       "  '0.3',\n",
       "  '0.5',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00'],\n",
       " ['0.7000', '0.3000', '0.4000', '0.5000', '0.6000'],\n",
       " ['0.8526', '0.2349', '0.9805', '0.0', '0.0'],\n",
       " ['0.6486', '0.8477', '0.4815', '0.5132', '0.9311'],\n",
       " ['0.00', '0.00', '0.67', '0.44', '0.45'],\n",
       " ['0.56', '0.21', '0.65', '0.41', '0.92'],\n",
       " ['0.5', '0.6', '0.2', '0.4', '0.9'],\n",
       " ['0.0', '0.0', '0.8', '0.4'],\n",
       " ['0.5', '0.6', '0.6', '0.7', '0.8'],\n",
       " ['0.5', '0.2', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6861', '0.8475', '0.5037', '0.5536', '0.9355'],\n",
       " ['0.86', '0.57', '0.48', '0.8', '0.39'],\n",
       " ['0.5', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.8537', '0.5826', '0.7685', '0.4537', '0.3231'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5821', '0.5179', '0.5431', '0.4818', '0.5204'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.9'],\n",
       " ['0.8', '0.7', '0.5', '0.6', '0.4'],\n",
       " ['0.7000', '0.9000', '0.5000', '0.4000', '0.3000'],\n",
       " ['0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.7', '0.4', '0.6', '0.3'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.7'],\n",
       " ['0.94', '0.91', '0.65', '0.55', '0.44'],\n",
       " ['0.5', '0.4', '0.8', '0.6', '0.7'],\n",
       " ['0.0000', '0.0000', '0.7000', '0.1000', '0.9000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.87', '0.64', '0.23', '0.38', '0.62'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6869', '0.8472', '0.5037', '0.5489', '0.9291'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.7795', '0.9566', '0.5609', '0.6014', '0.6981'],\n",
       " ['0.8', '0.9', '0.7', '0.6', '0.95'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.0', '0.8', '0.2', '0.4', '0.8'],\n",
       " ['0.5', '0.4', '0.6', '0.5', '0.7'],\n",
       " ['0.52', '0.64', '0.38', '0.45', '0.62'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5436', '0.9805', '0.3929', '0.5781', '0.6062'],\n",
       " ['0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0', '0.0', '0.2', '0.6', '0.4'],\n",
       " ['0.8534', '0.9355', '0.5139', '0.3747', '0.4738'],\n",
       " ['0.8537', '0.1111', '0.9802', '0.3344', '0.7775'],\n",
       " ['0.5', '0.4', '0.5', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.94', '0.64', '0.44', '0.56', '0.71'],\n",
       " ['0.6701', '0.8476', '0.4999', '0.5403', '0.9355'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.6869', '0.8476', '0.5031', '0.5487', '0.9728'],\n",
       " ['0.8', '0.9', '0.6', '0.5', '0.7'],\n",
       " ['0.5', '0.7', '0.6', '0.5', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " [],\n",
       " ['0.5', '0.4', '0.8', '0.6', '0.3'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.8', '0.6', '0.4', '0.1'],\n",
       " ['0.6701', '0.7795', '0.5209', '0.4996', '0.9564'],\n",
       " ['0.8', '0.5', '0.7', '0.6', '0.4'],\n",
       " ['0.86', '0.55', '0.45', '0.5', '0.71'],\n",
       " ['0.00', '0.55', '0.45', '0.05', '0.95'],\n",
       " ['0.94', '0.91', '0.55', '0.47', '0.64'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.8'],\n",
       " ['0.5', '0.6', '0.6', '0.7', '0.4'],\n",
       " ['0.9', '0.6', '0.7', '0.4', '0.8'],\n",
       " ['0.5376', '0.7609', '0.4202', '0.5614', '0.3929'],\n",
       " ['0.5', '0.6', '0.7', '0.4', '0.8'],\n",
       " ['0.8',\n",
       "  '0.9',\n",
       "  '0.7',\n",
       "  '0.6',\n",
       "  '0.8',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.4',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.9',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.9',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.9',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.9',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5'],\n",
       " ['0.8', '0.5', '0.9', '0.6', '0.8'],\n",
       " ['0.00', '0.50', '0.00', '0.50', '0.00'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.9'],\n",
       " ['0.8', '0.6', '0.5', '0.7', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.7', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.3', '0.5', '0.7', '0.6', '0.4'],\n",
       " ['0.6701', '0.7879', '0.4991', '0.5174', '0.9566'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.000', '0.000', '0.000', '0.000', '0.000'],\n",
       " ['0.87', '0.45', '0.43', '0.56', '0.38'],\n",
       " ['0.6488', '0.8702', '0.5203', '0.5439', '0.9727'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.5', '0.8', '0.4', '0.6'],\n",
       " ['0.6869', '0.8476', '0.5031', '0.5437', '0.0'],\n",
       " ['0.5898', '0.8476', '0.5037', '0.5423', '0.9729'],\n",
       " ['0.8', '0.6', '0.4', '0.7', '0.5'],\n",
       " ['0.6489', '0.7395', '0.7795', '0.9171', '0.3929'],\n",
       " ['0.8536', '0.5827', '0.7395', '0.7951', '0.4066'],\n",
       " ['0.94', '0.55', '0.23', '0.38', '0.6'],\n",
       " ['0.5', '0.4', '0.7', '0.6', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.8', '0.7', '0.1', '0.6', '0.3'],\n",
       " ['0.5', '0.7', '0.6', '0.4', '0.9'],\n",
       " ['0.86', '0.23', '0.78', '0.64', '0.16'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.7', '0.6', '0.5', '0.4'],\n",
       " ['0.86', '0.34', '0.46', '0.78', '0.44'],\n",
       " ['0.87', '0.45', '0.43', '0.38', '0.50'],\n",
       " ['0.8532', '0.5821', '0.7399', '0.7958', '0.6406'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8534', '0.7566', '0.3231', '0.6019', '0.2218'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.4', '0.6', '0.3', '0.8', '0.6', '0.5', '0.7', '0.4', '0.6'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.4'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6709', '0.8478', '0.4942', '0.5316', '0.9356'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8', '0.6', '0.7', '0.4', '0.9'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.1',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.3',\n",
       "  '0.5',\n",
       "  '0.2',\n",
       "  '0.7',\n",
       "  '0.4',\n",
       "  '0.5',\n",
       "  '0.6',\n",
       "  '0.2',\n",
       "  '0.7',\n",
       "  '0.4',\n",
       "  '0.5',\n",
       "  '0.6'],\n",
       " ['0.5421', '0.8502', '0.5207', '0.6065', '0.6421'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8', '0.7', '0.9', '0.6', '0.8'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.52', '0.23', '0.56', '0.65', '0.45'],\n",
       " ['0.5', '0.6', '0.4', '0.7', '0.7'],\n",
       " ['0.5', '0.8', '0.7', '0.4'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.7796', '0.5109', '0.7955', '0.5617', '0.4211'],\n",
       " ['0.5437', '0.8526', '0.5609', '0.6065', '0.8702'],\n",
       " ['0.8502', '0.9566', '0.6642', '0.6869', '0.8101'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000',\n",
       "  '0.0000',\n",
       "  '0.4000',\n",
       "  '0.6000',\n",
       "  '0.5000',\n",
       "  '0.0000',\n",
       "  '0.4000',\n",
       "  '0.2000',\n",
       "  '0.2000',\n",
       "  '0.8000'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.4',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.6',\n",
       "  '0.5',\n",
       "  '0.4',\n",
       "  '0.8',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.6',\n",
       "  '0.5',\n",
       "  '0.9',\n",
       "  '0.6',\n",
       "  '0.7',\n",
       "  '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.86', '0.52', '0.71', '0.23', '0.58'],\n",
       " ['0.5', '0.6', '0.5', '0.4', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.2', '0.9'],\n",
       " ['0.5', '0.8', '0.7', '0.6', '0.9'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.7', '0.8', '0.4', '0.5', '0.9'],\n",
       " ['0.8532', '0.5826', '0.7795', '0.5789', '0.3019'],\n",
       " ['0.6869', '0.8536', '0.5134', '0.5501', '0.9728'],\n",
       " ['0.5',\n",
       "  '0.4',\n",
       "  '0.8',\n",
       "  '0.2',\n",
       "  '0.6',\n",
       "  '0.5',\n",
       "  '0.4',\n",
       "  '0.8',\n",
       "  '0.2',\n",
       "  '0.6',\n",
       "  '0.5',\n",
       "  '0.4',\n",
       "  '0.8',\n",
       "  '0.2',\n",
       "  '0.6'],\n",
       " ['0.0', '0.0', '0.0', '0.5', '0.0'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.7', '0.8', '0.4', '0.5', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.2', '0.4', '0.6', '0.8'],\n",
       " ['0.6489', '0.7795', '0.4406', '0.5105', '0.8471'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6861', '0.8437', '0.5039', '0.5489', '0.9562'],\n",
       " ['0.4001', '0.5000', '0.7000', '0.3000', '0.6001'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.8', '0.1', '0.9', '0.2', '0.6'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5436', '0.4455', '0.6862', '0.8914', '0.0'],\n",
       " ['0.1111', '0.7778', '0.3333', '0.6667', '0.8889'],\n",
       " ['0.6869', '0.8476', '0.5022', '0.5437', '0.9356'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6486', '0.7662', '0.3231', '0.4737', '0.8479'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.9246', '0.8479', '0.7795', '0.8101', '0.3924'],\n",
       " ['0.8', '0.9', '0.6', '0.7', '0.7'],\n",
       " ['0.5421', '0.5899', '0.3929', '0.6065', '0.7582'],\n",
       " ['0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.9', '0.8', '0.9', '0.3', '0.8', '0.2'],\n",
       " ['0.7', '0.8', '0.4', '0.5', '0.9', '0.6', '0.7', '0.5', '0.4', '0.8'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.5421', '0.8507', '0.5032', '0.5206', '0.8109'],\n",
       " ['0.1111',\n",
       "  '0.7777',\n",
       "  '0.5555',\n",
       "  '0.6666',\n",
       "  '0.8888',\n",
       "  '0.2',\n",
       "  '0.6',\n",
       "  '0.4',\n",
       "  '0.7',\n",
       "  '0.5'],\n",
       " ['0.4', '0.9', '0.1', '0.8', '0.6'],\n",
       " ['0.00', '0.56', '0.39', '0.64', '0.44'],\n",
       " ['0.6487', '0.7795', '0.6860', '0.5506', '0.8101'],\n",
       " ['0.6489', '0.7297', '0.5206', '0.5439', '0.9721'],\n",
       " ['0.6860', '0.8475', '0.5207', '0.5656', '0.0'],\n",
       " ['0.6427', '0.5134', '0.7566', '0.3239', '0.5898'],\n",
       " ['0.43', '0.55', '0.47', '0.56', '0.64'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.7', '0.8', '0.3', '0.5', '0.4', '0.2'],\n",
       " ['0.5', '0.6', '0.4', '0.5', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.7', '0.6', '0.6', '0.5'],\n",
       " ['0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.2', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8', '0.9', '0.6', '0.7', '0.4'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.6', '0.6', '0.7', '0.5'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.1'],\n",
       " ['0.8', '0.6', '0.9', '0.8', '0.7'],\n",
       " ['0.8704', '0.7209', '0.9877', '0.0000', '0.0000'],\n",
       " ['0.5436', '0.6489', '0.6862', '0.5611', '0.7605'],\n",
       " ['0.5', '0.4', '0.6', '0.5', '0.4'],\n",
       " ['0.7000', '0.4000', '0.5000', '0.6000', '0.3000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.87', '0.62', '0.65', '0.60', '0.44'],\n",
       " ['0.5', '0.6', '0.2', '0.3', '0.7'],\n",
       " ['0.5', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.7', '0.8', '0.4', '0.5', '0.9'],\n",
       " ['0.1111', '0.2222', '0.3333', '0.4444', '0.5555'],\n",
       " ['0.8', '0.6', '0.7', '0.5', '0.9'],\n",
       " ['0.55', '0.60', '0.45', '0.55', '0.45'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8522', '0.2345', '0.3456', '0.1234', '0.7567'],\n",
       " ['0.5', '0.6', '0.4', '0.5', '0.7'],\n",
       " ['0.87', '0.92', '0.27', '0.64', '0.33'],\n",
       " ['0.8', '0.7', '0.5', '0.6', '0.4'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.4', '0.5', '0.5', '0.6'],\n",
       " ['0.8', '0.7', '0.5', '0.6', '0.7'],\n",
       " ['0.00', '0.55', '0.45', '0.10', '0.55'],\n",
       " ['0.1004',\n",
       "  '0.1000',\n",
       "  '0.1000',\n",
       "  '0.1001',\n",
       "  '0.1002',\n",
       "  '0.1004',\n",
       "  '0.1000',\n",
       "  '0.1000',\n",
       "  '0.1001',\n",
       "  '0.1002'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.8', '0.9', '0.6', '0.5', '0.7'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5'],\n",
       " ['0.87', '0.45', '0.43', '0.38', '0.50'],\n",
       " ['0.7397', '0.9259', '0.1624', '0.6523', '0.739'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6869', '0.8478', '0.5035', '0.5486', '0.9561'],\n",
       " ['0.87', '0.45', '0.69', '0.38', '0.95'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.6701', '0.8439', '0.5035', '0.5592', '0.9728'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.00', '0.00', '0.00', '0.00', '0.50'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.4', '0.7', '0.6', '0.5', '0.9'],\n",
       " ['0.94', '0.56', '0.78', '0.82', '0.23'],\n",
       " ['0.6861', '0.7395', '0.6719', '0.6107', '0.6066'],\n",
       " ['0.86', '0.64', '0.38', '0.62', '0.67'],\n",
       " ['0.5', '0.6', '0.7', '0.7', '0.2'],\n",
       " ['0.6481', '0.6704', '0.5789', '0.5122', '0.7393'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.7000', '0.8500', '0.5000', '0.6000', '0.9500'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7'],\n",
       " ['0.45', '0.5', '0.25', '0.25', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.5', '0.6'],\n",
       " ['0.8', '0.6', '0.5', '0.7', '0.4'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.6'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.6869', '0.8478', '0.6292', '0.5615', '0.9723'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6489', '0.8476', '0.5175', '0.5592', '0.9356'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6486', '0.3459', '0.5431', '0.4403', '0.5335'],\n",
       " ['0.5', '0.8', '0.7', '0.6', '0.4'],\n",
       " ['0.8', '0.6', '0.7', '0.4', '0.3'],\n",
       " ['0.4009', '0.1001', '0.7005', '0.1001', '0.5000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.6', '0.7', '0.4', '0.8'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.8506', '0.5157', '0.7399', '0.7399', '0.1111'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.7000', '0.4000', '0.6000', '0.5000', '0.5000'],\n",
       " ['0.5', '0.6', '0.7', '0.2', '0.4'],\n",
       " ['0.0000', '0.0000', '0.0000'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.9',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.4',\n",
       "  '0.2',\n",
       "  '0.7',\n",
       "  '0.3',\n",
       "  '0.9'],\n",
       " ['0.6486', '0.7395', '0.5789', '0.6065', '0.561'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.55', '0.7', '0.5', '0.45', '0.95'],\n",
       " ['0.56', '0.21', '0.76', '0.43', '0.25'],\n",
       " ['0.5', '0.4', '0.3', '0.2', '0.1'],\n",
       " ['0.6489', '0.7395', '0.4407', '0.5506', '0.7399'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.8', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.8', '0.7', '0.4', '0.6', '0.9'],\n",
       " ['0.4000', '0.1000', '0.7000', '0.5000', '0.3000'],\n",
       " ['0.87', '0.91', '0.60', '0.64', '0.66'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.2'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.8', '0.4', '0.9', '0.6', '0.7'],\n",
       " ['0.8', '0.6', '0.9', '0.7', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5', '0.6', '0.8', '0.7', '0.7', '0.9'],\n",
       " ['0.0', '0.0', '0.5', '0.0'],\n",
       " ['0.8', '0.6', '0.4', '0.7', '0.9'],\n",
       " ['0.56', '0.64', '0.76', '0.68', '0.45'],\n",
       " ['0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6489', '0.7395', '0.5789', '0.4816', '0.7203'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.7'],\n",
       " ['0.87', '0.64', '0.45', '0.56', '0.67'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.9'],\n",
       " ['0.7000000000000001',\n",
       "  '0.10000000000000002',\n",
       "  '0.5000000000000001',\n",
       "  '0.90000000000000002',\n",
       "  '0.30000000000000004'],\n",
       " ['0.87', '0.45', '0.43', '0.56', '0.38'],\n",
       " ['0.6489', '0.5135', '0.3017', '0.3231', '0.0'],\n",
       " ['0.5', '0.6', '0.6', '0.7', '0.5'],\n",
       " ['0.5', '0.8', '0.6', '0.7', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.2', '0.8'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.7', '0.4', '0.6', '0.8'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5376', '0.4007', '0.7795', '0.6019', '0.2312'],\n",
       " ['0.5', '0.6', '0.4', '0.6', '0.7'],\n",
       " ['0.0', '0.0', '0.5', '0.0'],\n",
       " ['0.9245', '0.3507', '0.9682', '0.1834', '0.1111'],\n",
       " ['0.8', '0.9', '0.7', '0.6', '0.8'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.9',\n",
       "  '0.7',\n",
       "  '0.4',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.1',\n",
       "  '0.9',\n",
       "  '0.7',\n",
       "  '0.4',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.5',\n",
       "  '0.9'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6860', '0.7391', '0.4949', '0.5137', '0.9565'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6869', '0.7391', '0.4945', '0.5137', '0.3456'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.7'],\n",
       " ['0.6706', '0.8475', '0.5037', '0.5174', '0.9319'],\n",
       " ['0.8534', '0.9689', '0.5865', '0.5514', '0.9721'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.9'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.45', '0.55', '0.2', '0.5', '0.6'],\n",
       " ['0.6701', '0.8476', '0.5207', '0.5496', '0.9291'],\n",
       " ['0.8', '0.6', '0.5', '0.4', '0.9'],\n",
       " ['0.5421', '0.1919', '0.6296', '0.7395', '0.7398'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5000', '0.0000', '0.0000', '0.5000', '0.0000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8526', '0.3927', '0.1114', '0.8025', '0.4009'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5', '0.8', '0.6', '0.7', '0.7', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6862', '0.6109', '0.6066', '0.5611', '0.8704'],\n",
       " ['0.5', '0.7', '0.6', '0.5', '0.6'],\n",
       " ['0.5', '0.4', '0.2', '0.6', '0.1'],\n",
       " ['0.6862', '0.8479', '0.5125', '0.5506', '0.9354'],\n",
       " ['0.6706',\n",
       "  '0.8471',\n",
       "  '0.5037',\n",
       "  '0.5365',\n",
       "  '0.9352',\n",
       "  '0.6863',\n",
       "  '0.8438',\n",
       "  '0.5121',\n",
       "  '0.5496',\n",
       "  '0.9642',\n",
       "  '0.6403',\n",
       "  '0.8529',\n",
       "  '0.4171',\n",
       "  '0.4737',\n",
       "  '0.9686',\n",
       "  '0.6403',\n",
       "  '0.8529',\n",
       "  '0.4141',\n",
       "  '0.4737',\n",
       "  '0.9686'],\n",
       " ['0.8', '0.2', '0.6', '0.4', '0.1'],\n",
       " ['0.6869', '0.3231', '0.4782', '0.4406', '0.6595'],\n",
       " ['0.5', '0.6', '0.4', '0.5', '0.5'],\n",
       " ['0.5376', '0.7682', '0.3925', '0.5539', '0.7394'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.3', '0.1', '0.7', '0.2', '0.4'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.7209', '0.7395', '0.5206', '0.5034', '0.7796'],\n",
       " ['0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.9', '0.5', '0.4', '0.6', '0.7', '0.9'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.8', '0.6', '0.4', '0.7'],\n",
       " ['0.5', '0.4', '0.5', '0.6', '0.7'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.2'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.7', '0.6', '0.8', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.5', '0.6', '0.4', '0.7', '0.8'],\n",
       " ['0.7002', '0.6859', '0.5515', '0.5038', '0.8701'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.6869', '0.7395', '0.6066', '0.5364', '0.6421'],\n",
       " ['0.7000', '0.8500', '0.5000', '0.5500', '0.9500'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.4', '0.7', '0.6', '0.3'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.1000', '0.4000', '0.5000', '0.7000', '0.2000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6480', '0.7795', '0.4941', '0.5032', '0.9259'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.5'],\n",
       " [],\n",
       " ['0.5', '0.6', '0.6', '0.4', '0.7'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5421', '0.5174', '0.6712', '0.5506', '0.3636'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6869', '0.6109', '0.6062', '0.6984', '0.7585'],\n",
       " ['0.52', '0.43', '0.68', '0.35', '0.64'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.4', '0.3', '0.7'],\n",
       " ['0.9246', '0.4009', '0.0', '0.0', '0.0'],\n",
       " ['0.6862', '0.5615', '0.6014', '0.5699', '0.3016'],\n",
       " ['0.5', '0.6', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.4002', '0.1001', '0.2001', '0.7001', '0.9001'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.8', '0.6', '0.7'],\n",
       " ['0.5', '0.6', '0.4', '0.8', '0.7'],\n",
       " ['0.8532', '0.2159', '0.7585', '0.3665', '0.1111'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.8', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.7'],\n",
       " ['0.8526', '0.3231', '0.6019', '0.5202', '0.2639'],\n",
       " ['0.6704', '0.8471', '0.4949', '0.5209', '0.9252'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.6', '0.4', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6481', '0.7796', '0.4815', '0.5207', '0.9252'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6489', '0.7795', '0.4404', '0.6062', '0.8101'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5822', '0.5125', '0.7399', '0.6019', '0.6981'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.8534', '0.5822', '0.9357', '0.5895', '0.5201'],\n",
       " ['0.86', '0.44', '0.78', '0.38', '0.46'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.8', '0.2', '0.3', '0.6', '0.4'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.4004', '0.1001', '0.7005', '0.2002', '0.5000'],\n",
       " ['0.5', '0.4', '0.6', '0.5', '0.8'],\n",
       " ['0.5', '0.7', '0.7', '0.6', '0.6'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.2'],\n",
       " ['0.6862', '0.5619', '0.4826', '0.9807', '0.5502'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5421', '0.8532', '0.5037', '0.5206', '0.9688'],\n",
       " ['0.7399', '0.9174', '0.4738', '0.4815', '0.8451'],\n",
       " ['0.87', '0.47', '0.52', '0.64', '0.35'],\n",
       " ['0.6', '0.7', '0.5', '0.6', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.7', '0.4', '0.6', '0.2'],\n",
       " ['0.8', '0.9', '0.6', '0.7', '0.8'],\n",
       " ['0.6869', '0.8476', '0.5037', '0.5507', '0.9356'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.6', '0.4', '0.7', '0.3'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.86', '0.55', '0.56', '0.62', '0.64'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6489', '0.8478', '0.4975', '0.5497', '0.9566'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.5', '0.8', '0.6'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.7000', '0.8500', '0.5000', '0.5500', '0.9500'],\n",
       " ['0.8702', '0.5789', '0.7795', '0.3924', '0.3011'],\n",
       " ['0.8', '0.6', '0.7', '0.4', '0.9'],\n",
       " ['0.8522', '0.5821', '0.7399', '0.7958', '0.4176'],\n",
       " ['0.6861', '0.7399', '0.4822', '0.5204', '0.5436'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9', '0.8', '0.9', '0.7', '0.6', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6865', '0.8477', '0.5036', '0.5535', '0.9562'],\n",
       " ['0.6427', '0.5179', '0.8476', '0.5768', '0.3261'],\n",
       " ['0.8', '0.6', '0.5', '0.6', '0.4'],\n",
       " ['0.5', '0.6', '0.4', '0.8', '0.6'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.4', '0.6', '0.7', '0.7'],\n",
       " ['0.8', '0.2', '0.7', '0.4', '0.6'],\n",
       " ['0.6862', '0.8479', '0.9106', '0.6108', '0.4941'],\n",
       " ['0.5', '0.6', '0.7', '0.5', '0.4'],\n",
       " ['0.5', '0.6', '0.7', '0.4', '0.9'],\n",
       " ['0.3', '0.7', '0.4', '0.5', '0.8'],\n",
       " ['0.5', '0.6', '0.7', '0.6', '0.4'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5376', '0.5207', '0.0', '0.7795', '0.0'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.8', '0.6', '0.4', '0.7', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6486', '0.7299', '0.5204', '0.5512', '0.8457'],\n",
       " ['0.5', '0.8', '0.6', '0.7', '0.4'],\n",
       " ['0.7000', '0.1000', '0.5000', '0.9000', '0.3000'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.8', '0.4', '0.6', '0.7'],\n",
       " ['0.8', '0.6', '0.4', '0.5', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.4', '0.8'],\n",
       " ['0.6', '0.7', '0.5', '0.4', '0.8'],\n",
       " ['0.43', '0.55', '0.62', '0.45', '0.44'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.2', '0.1', '0.8', '0.6', '0.5', '0.4', '0.2', '0.7', '0.5', '0.6'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000'],\n",
       " ['0.6487', '0.8431', '0.5426', '0.5592', '0.9729'],\n",
       " ['0.6701', '0.8526', '0.5039', '0.5202', '0.9295'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.6861', '0.7395', '0.4949', '0.5619', '0.9299'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5426', '0.7395', '0.7299', '0.3234', '0.0'],\n",
       " ['0.4', '0.8', '0.6', '0.7', '0.5'],\n",
       " ['0.7000',\n",
       "  '0.5000',\n",
       "  '0.4000',\n",
       "  '0.1000',\n",
       "  '0.2000',\n",
       "  '0.2000',\n",
       "  '0.7000',\n",
       "  '0.5000',\n",
       "  '0.4000',\n",
       "  '0.3000',\n",
       "  '0.1000',\n",
       "  '0.2000',\n",
       "  '0.7000',\n",
       "  '0.5000',\n",
       "  '0.4000',\n",
       "  '0.2000',\n",
       "  '0.1000',\n",
       "  '0.3000',\n",
       "  '0.7000',\n",
       "  '0.5000',\n",
       "  '0.3000',\n",
       "  '0.2000',\n",
       "  '0.7000',\n",
       "  '0.1000',\n",
       "  '0.4000',\n",
       "  '0.7000',\n",
       "  '0.3000',\n",
       "  '0.2000',\n",
       "  '0.9000',\n",
       "  '0.1000',\n",
       "  '0.7000',\n",
       "  '0.3000',\n",
       "  '0.2000',\n",
       "  '0.9000',\n",
       "  '0.1000',\n",
       "  '0.5000'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.6', '0.8', '0.4', '0.7'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5'],\n",
       " ['0.55', '0.25', '0.45', '0.65', '0.5'],\n",
       " ['0.0', '0.0', '0.0', '0.0'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.2', '0.6', '0.7', '0.4'],\n",
       " ['0.5', '0.4', '0.8', '0.6', '0.9'],\n",
       " ['0.6722', '0.8322', '0.4860', '0.5298', '0.9323'],\n",
       " ['0.5', '0.4', '0.6', '0.6', '0.6'],\n",
       " ['0.56', '0.22', '0.85', '0.41', '0.25'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5', '0.6', '0.7', '0.8', '0.9'],\n",
       " ['0.5',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.9',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.9',\n",
       "  '0.7',\n",
       "  '0.5',\n",
       "  '0.8',\n",
       "  '0.6',\n",
       "  '0.9'],\n",
       " ['0.5', '0.5', '0.5', '0.5', '0.5']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527b1d9-3cd4-4233-befa-b6367b0c061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\",\n",
    "                     index_col=0)\n",
    "\n",
    "FI_test['label'] = FI_test['OCEAN'].map(lambda x : [float(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf4295-2fad-4775-96f1-296bb2743f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_arr = []\n",
    "error_idx = []\n",
    "\n",
    "for i in range(len(FI_test)):\n",
    "    try:\n",
    "        MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2a459-7010-448b-a4e0-5aa5501439ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36876c0-5dc5-4aee-9511-26a771ce919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.76689361, 0.74817063, 0.72982805, 0.82210586, 0.6573215 ]),\n",
       " 0.7448639302694146)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_mae = np.array(MAE_arr).mean(axis=0)\n",
    "avg_mae = np.mean(factor_mae)\n",
    "\n",
    "factor_mae, avg_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5b674-cfd3-4384-a885-5151160620aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(error_idx) !=0:\n",
    "    re_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])\n",
    "    \n",
    "    for data in tqdm(FI_test['transcription'][error_idx].to_list()):\n",
    "        user = data\n",
    "        re_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['\n",
    "        outputs = model(re_inputs, **generation_kwargs)\n",
    "        out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "    \n",
    "        tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "        re_df = pd.concat([re_df, tmp_df])\n",
    "\n",
    "    re_score = []\n",
    "    p = re.compile('0[.]\\d*')\n",
    "    \n",
    "    for content in re_df['Inference'].to_list():\n",
    "        tmp = p.findall(content)\n",
    "        re_score.append(tmp)\n",
    "        \n",
    "    for i, idx in enumerate(error_idx):\n",
    "        score[idx] = re_score[i]\n",
    "\n",
    "    MAE_arr = []\n",
    "    error_idx = []\n",
    "    \n",
    "    for i in range(len(FI_test)):\n",
    "        try:\n",
    "            MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            error_idx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17dc8d-1bc1-4743-8ee2-118bbfcd4241",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e6863-7a31-447f-aee6-ff6661d2f85c",
   "metadata": {},
   "source": [
    "### One-shot LLM Inference (Kernel Restart Required for GPU Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e382480c-9dff-45e7-83d5-cc96ae477ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [1:01:02<00:00,  5.80s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\")  # 데이터 불러오기 (First Impression V2 데이터의 Test set 불러오기)\n",
    "\n",
    "model_id = 'Bllossom/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M'  # 모델 이름\n",
    "GGUF = \"data/visi/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf\" # GGUF 경로\n",
    "model = Llama(\n",
    "    model_path='/data/visi2/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf',\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=-1,        # Number of model layers to offload to GPU\n",
    "    verbose=False, \n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "one_shot_text = \"공연 보는 건 어떨까요? 네 좋아요\"\n",
    "\n",
    "zero_shot2 = '당신은 문장에 대해 OCEAN 성격 요소 각각에 대한 점수를 알려주는 전문가 입니다. \\n\\\n",
    "OCEAN 성격 요소는 다음에 대한 사항을 확인합니다. O(Openness), C(Conscientiousness), E(Extraversion), A(Agreeableness), N(Neuroticism) \\n\\\n",
    "주어진 문장을 읽고, 문장에서 나타나는 OCEAN 성격 요소들을 분석하여 각각의 요소에 0에서 1 사이의 점수를 매기세요. \\n\\\n",
    "점수는 문장에서 해당 요소가 얼마나 잘 드러나는지를 기반으로 하며, 0에 가까울수록 전혀 드러나지 않음을, 1에 가까울수록 매우 강하게 드러남을 의미합니다. \\n\\\n",
    "다음의 예시와 같이 출력 값으로 주어진 문장에 대한 OCEAN 성격 요소 5가지를 각각의 점수로 나타내어야합니다. [O: 0.6722, C: 0.8322, E: 0.4860, A: 0.5298, N: 0.3541] \\n\\\n",
    "'\n",
    "\n",
    "ko_prompt_one_shot = zero_shot2 + '문장: \"' + one_shot_text + '\",\\n 결과- [O: 0.9792, C: 0.9792, E: 0.8334, A: 0.6458, N: 0.2083] \\n'\n",
    "\n",
    "generation_kwargs = {  # Decoding/Sampling Strategy\n",
    "    \"max_tokens\" : 512, # 최대 생성 토큰, 1024\n",
    "    \"temperature\" : 0.9,\n",
    "    \"repeat_penalty\" : 1.3,\n",
    "    \"top_k\" :50,\n",
    "    \"top_p\" :0.92,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])  # 결과를 저장할 데이터프레임\n",
    "\n",
    "for content in tqdm(FI_test['transcription'].to_list()):\n",
    "    user = content\n",
    "    inputs = tokenizer.encode(zero_shot2 + '문장: \"' + user + '\",\\n 결과- [O: ', return_tensors='pt').to(\"cuda\")  # 입력 데이터 토크나이징\n",
    "    raw_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['  # 토크나이징 전 텍스트\n",
    "    outputs = model(raw_inputs, **generation_kwargs)\n",
    "    out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "\n",
    "    tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "    result_df = pd.concat([result_df, tmp_df])\n",
    "\n",
    "# KULLM, KoSOLAR (SOLAR-10.7B) : 약 21GB GPU 메모리 소모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd2da8-f832-45b1-9092-fd9c8751d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Inference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3528e4cf-5d5c-409c-bd1d-824d07f15e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "p = re.compile('0[.]\\d*')\n",
    "\n",
    "for content in result_df['Inference'].to_list():\n",
    "    tmp = p.findall(content)\n",
    "    score.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24cc53-acfd-4d5e-b40c-72ca8c80e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeecb7c-5da2-4a61-9ad3-d9f2efb816dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\",\n",
    "                     index_col=0)\n",
    "FI_test['label'] = FI_test['OCEAN'].map(lambda x : [float(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689ae7d-20f9-4c93-8333-8b1202b9f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_arr = []\n",
    "error_idx = []\n",
    "\n",
    "for i in range(len(FI_test)):\n",
    "    try:\n",
    "        MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aab54d-76dc-4ec9-9bc8-eb5461e0915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4a02c-ae0c-4191-afca-c5965505ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(error_idx) !=0:\n",
    "    re_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])\n",
    "    \n",
    "    for data in tqdm(FI_test['transcription'][error_idx].to_list()):\n",
    "        user = data\n",
    "        re_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['\n",
    "        outputs = model(re_inputs, **generation_kwargs)\n",
    "        out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "    \n",
    "        tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "        re_df = pd.concat([re_df, tmp_df])\n",
    "\n",
    "    re_score = []\n",
    "    p = re.compile('0[.]\\d*')\n",
    "    \n",
    "    for content in re_df['Inference'].to_list():\n",
    "        tmp = p.findall(content)\n",
    "        re_score.append(tmp)\n",
    "        \n",
    "    for i, idx in enumerate(error_idx):\n",
    "        score[idx] = re_score[i]\n",
    "\n",
    "    MAE_arr = []\n",
    "    error_idx = []\n",
    "    \n",
    "    for i in range(len(FI_test)):\n",
    "        try:\n",
    "            MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c54f7-4f91-4caa-8302-dbcee8e7d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_mae = np.array(MAE_arr).mean(axis=0)\n",
    "avg_mae = np.mean(factor_mae)\n",
    "\n",
    "factor_mae, avg_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6efad-e500-4f34-9de1-1ca5f384d976",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078511cd-4367-4681-8e08-94e036536182",
   "metadata": {},
   "source": [
    "### five-shot LLM Inference (Kernel Restart Required for GPU Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3e88f-3af2-4409-a8c1-63e309e612d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import logging\n",
    "logging.disable(logging.INFO) \n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\")  # 데이터 불러오기 (First Impression V2 데이터의 Test set 불러오기)\n",
    "\n",
    "model_id = 'Bllossom/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M'  # 모델 이름\n",
    "GGUF = \"data/visi/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf\" # GGUF 경로\n",
    "model = Llama(\n",
    "    model_path='/data/visi2/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf',\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=-1        # Number of model layers to offload to GPU\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "few_shot_text0 = \"네 그럼 14위는 어떤 분으로 하는 게 좋을까요?\"\n",
    "few_shot_text1 = \"편의점 귀엽다\"\n",
    "few_shot_text2 = \"술 팔까요? 아 근데\"\n",
    "few_shot_text3 = \"진짜요? 그러면 해주실 수 있어요.\"\n",
    "few_shot_text4 = \"그렇죠 그렇죠 그렇죠 여기 여기 메인 무대가 무대랑 좌석인 거죠?\"\n",
    "\n",
    "zero_shot2 = '당신은 문장에 대해 OCEAN 성격 요소 각각에 대한 점수를 알려주는 전문가 입니다. \\n\\\n",
    "OCEAN 성격 요소는 다음에 대한 사항을 확인합니다. O(Openness), C(Conscientiousness), E(Extraversion), A(Agreeableness), N(Neuroticism) \\n\\\n",
    "주어진 문장을 읽고, 문장에서 나타나는 OCEAN 성격 요소들을 분석하여 각각의 요소에 0에서 1 사이의 점수를 매기세요. \\n\\\n",
    "점수는 문장에서 해당 요소가 얼마나 잘 드러나는지를 기반으로 하며, 0에 가까울수록 전혀 드러나지 않음을, 1에 가까울수록 매우 강하게 드러남을 의미합니다. \\n\\\n",
    "다음의 예시와 같이 출력 값으로 주어진 문장에 대한 OCEAN 성격 요소 5가지를 각각의 점수로 나타내어야합니다. [O: 0.6722, C: 0.8322, E: 0.4860, A: 0.5298, N: 0.9323] \\n\\\n",
    "'\n",
    "\n",
    "ko_prompt_few_shot = zero_shot2 + '문장: \"' + few_shot_text0 + '\",\\n 결과- [O: 0.9762 , C: 0.9792 , E: 0.8333 , A: 0.6458 , N: 0.2083 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text1 + '\",\\n 결과- [O: 0.6667 , C: 0.7292, E: 0.8542, A: 0.5625, N: 0.2708] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text2 + '\",\\n 결과- [O: 0.5625, C: 0.8333, E: 0.8125, A: 0.3125, N: 0.2708 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text3 + '\",\\n 결과- [O: 0.7917, C: 0.5625, E: 0.8542, A: 0.7083, N: 0.3750] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text4 + '\",\\n 결과- [O: 0.9375, C: 0.9583, E: 0.8750, A: 0.3542, N: 0.1875 ] \\n'\n",
    "\n",
    "\n",
    "generation_kwargs = {  # Decoding/Sampling Strategy\n",
    "    \"max_tokens\" : 512, # 최대 생성 토큰, 1024\n",
    "    \"temperature\" : 0.9,\n",
    "    \"repeat_penalty\" : 1.3,\n",
    "    \"top_k\" :50,\n",
    "    \"top_p\" :0.92,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])  # 결과를 저장할 데이터프레임\n",
    "\n",
    "for content in tqdm(FI_test['transcription'].to_list()):\n",
    "    user = content\n",
    "    inputs = tokenizer.encode(zero_shot2 + '문장: \"' + user + '\",\\n 결과- [O: ', return_tensors='pt').to(\"cuda\")  # 입력 데이터 토크나이징\n",
    "    raw_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['  # 토크나이징 전 텍스트\n",
    "    outputs = model(raw_inputs, **generation_kwargs)\n",
    "    out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "    result_df = pd.concat([result_df, tmp_df])\n",
    "\n",
    "# KULLM, KoSOLAR (SOLAR-10.7B) : 약 21GB GPU 메모리 소모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3d616-c3ab-4c5e-99d9-3c33548c5900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['Inference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ebdb9-c0fd-4fed-ba0e-027d28eb9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "p = re.compile('0[.]\\d*')\n",
    "\n",
    "for content in result_df['Inference'].to_list():\n",
    "    tmp = p.findall(content)\n",
    "    score.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547eddb-5874-47d8-97a9-df236dd8a853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a0825-a757-4f93-82a1-209ac0225df7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\",\n",
    "                     index_col=0)\n",
    "# FI_test['label'] = FI_test[['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']].apply( lambda row: ' '.join(row.values.astype('str')), axis=1)\n",
    "\n",
    "# FI_test['label'] = FI_test['label'].str.split(' ')\n",
    "FI_test['label'] = FI_test['OCEAN'].map(lambda x : [float(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064c3f3-3905-444f-8c9c-bd243cbacba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAE_arr = []\n",
    "error_idx = []\n",
    "\n",
    "for i in range(len(FI_test)):\n",
    "    try:\n",
    "        MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db3421-eb63-4704-98e3-02e038390ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb0b92-d039-4129-a36c-ba6760944a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(error_idx) !=0:\n",
    "    re_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])\n",
    "    \n",
    "    for data in tqdm(FI_test['transcription'][error_idx].to_list()):\n",
    "        user = data\n",
    "        re_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- ['\n",
    "        outputs = model(raw_inputs, **generation_kwargs)\n",
    "\n",
    "        out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "    \n",
    "        tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "        re_df = pd.concat([re_df, tmp_df])\n",
    "\n",
    "    re_score = []\n",
    "    p = re.compile('0[.]\\d*')\n",
    "    \n",
    "    for content in re_df['Inference'].to_list():\n",
    "        tmp = p.findall(content)\n",
    "        re_score.append(tmp)\n",
    "        \n",
    "    for i, idx in enumerate(error_idx):\n",
    "        score[idx] = re_score[i]\n",
    "\n",
    "    MAE_arr = []\n",
    "    error_idx = []\n",
    "    \n",
    "    for i in range(len(FI_test)):\n",
    "        try:\n",
    "            MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16725e-bc1f-402c-9f95-703e09f3a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_mae = np.array(MAE_arr).mean(axis=0)\n",
    "avg_mae = np.mean(factor_mae)\n",
    "\n",
    "factor_mae, avg_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e8690-74ab-43d5-a770-494701ed3a08",
   "metadata": {},
   "source": [
    "### ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08a594-99b1-40e8-95fd-be6d9ad80c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"너는 지금부터 문장에 대해 BIG 5 성격 검사의 결과를 보여주는 전문 계산기야. 너는 전문가로써 BIG 5에 대한 정보를 충분히 알고있고 \\\n",
    "주어진 문장에 대해 5가지 요소를 가지는 BIG 5 성격 검사로 개성을 평가해야만 해. \\\n",
    "이 때, 문장이 주어지면 각각의 요소(개방성, 성실성, 우호성, 외향성, 신경증)에 대해 0부터 1사이의 값을 가지도록 숫자로 평가해야하고, \\\n",
    "모든 요소에 대해 최대한 세밀하고 정확하게 값을 출력해야 해. \\\n",
    "결과를 출력할 때, BIG 5에 대한 설명이나 이유에 대해서는 필요 없이 숫자 값만 보여줘. <요소 - 숫자> 형식으로 출력해.\\\n",
    "문장 : 오늘 워크샵은 정말 기대돼!>\"\n",
    "\n",
    "p2 = \"당신은 문장에 대해 BIG 5 성격 검사의 결과를 보여주는 전문가 입니다. 주어진 문장을 읽고, 다음과 같은 OCEAN 요소들을 각각 0에서 1 사이의 값으로 나타내세요. O(Openness): 개방성, C(Conscientiousness): 성실성, \\\n",
    "E(Extraversion): 외향성, A(Agreeableness): 친화성, N(Neuroticism): 신경성, 문장을 이용하여 각 요소의 점수를 계산할 때, 다음과 같은 접근을 사용할 수 있습니다: \\\n",
    "Openness (O): 문장에 포함된 창의성, 호기심, 복잡성에 대한 언급 등을 고려합니다. Conscientiousness (C): 문장에서 나타나는 계획성, 철저함, 조직성을 고려합니다. \\\n",
    "Extraversion (E): 문장에서 외향적인 특성, 사회적 활동에 대한 언급을 고려합니다. Agreeableness (A): 문장에서 타인에 대한 관심, 협동성, 친화력을 고려합니다. \\\n",
    "Neuroticism (N): 문장에 포함된 감정적 불안, 긴장, 우울 등을 고려합니다. \\\n",
    "이러한 기준을 이용하여 주어진 문장을 분석하여 각 요소에 대한 0에서 1 사이의 값을 계산해보세요. \\\n",
    "계산된 값은 다음의 예시처럼 다섯 개의 요소에 대한 배열로 표현되어야 합니다. \\\n",
    "예시) 다른 방에서 미친 듯이 달려가서 없는지 확인했는데 없는 것 같았어요 이제 잠을 충분히 못 자서 가위를 어딘가로 옮겼을 수도 있지만 맹세컨대 - [0.8222, 0.6699, 0.4860, 0.6458, 0.6813]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a494656-4ede-4147-9a46-a503ccb96584",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = '당신은 문장에 대해 OCEAN 성격 요소 각각에 대한 점수를 알려주는 전문가 입니다. \\n\\\n",
    "OCEAN 성격 요소는 다음에 대한 사항을 확인합니다. O(Openness), C(Conscientiousness), E(Extraversion), A(Agreeableness), N(Neuroticism) \\n\\\n",
    "주어진 문장을 읽고, 문장에서 나타나는 OCEAN 성격 요소들을 분석하여 각각의 요소에 0에서 1 사이의 점수를 매기세요. \\n\\\n",
    "점수는 문장에서 해당 요소가 얼마나 잘 드러나는지를 기반으로 하며, 0에 가까울수록 전혀 드러나지 않음을, 1에 가까울수록 매우 강하게 드러남을 의미합니다. \\n\\\n",
    "다음의 예시와 같이 출력 값으로 주어진 문장에 대한 OCEAN 성격 요소 5가지를 각각의 점수로 나타내어야합니다. [O: 0.6722, C: 0.8322, E: 0.4860, A: 0.5298, N: 0.9323] \\n\\\n",
    "'\n",
    "one_shot_text = \"현재 가장 좋아하는 책 사실 몇 달 전에 서점에서 이 책을 샀는데 읽을 기회가 없었는데 읽기 시작했어요 한번 시작하면 내려놓고 싶지 않은 책 조이스 마이어의 <용감하게 살기>라는 책이에요.\"\n",
    "\n",
    "zero = base_prompt + '문장: \"' + \"<EXAMPLE SENTENCE OF FI_TEST DATASET>\" + '\",\\n 결과- [O: '\n",
    "\n",
    "one = base_prompt + '문장: \"' + one_shot_text + '\",\\n 결과- [O: 0.6333, C: 0.7184, E: 0.4019, A: 0.4176, N: 0.5313] \\n' + '문장: \"' + \"<EXAMPLE SENTENCE OF FI_TEST DATASET>\" + '\",\\n 결과- [O: '\n",
    "\n",
    "\n",
    "\n",
    "print(\"Zero shot Input: \", \"\\n\", zero )\n",
    "print(\"\\n\\n\" ,\"=========================\"*15, \"\\n\\n\")\n",
    "print(\"One shot Input: \", \"\\n\", one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042fee-d714-425d-a470-96f4679f7d9c",
   "metadata": {},
   "source": [
    "### prompt example mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcb70d-8c8a-4871-a4ae-51d144de5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val = pd.read_csv(\"/data/visi2/FI/val_ko_pp.csv\",\n",
    "                 index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65399b71-5d71-4cca-bfe2-10202cb9d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ff3d7-40a4-4e15-9268-d836dedee2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_high = val[val['openness'] == val['openness'].max()]\n",
    "open_low = val.sort_values(by='openness')\n",
    "cons_high = val[val['conscientiousness'] == val['conscientiousness'].max()]\n",
    "cons_low = val[val['conscientiousness'] == val['conscientiousness'].min()]\n",
    "extra_high = val[val['extraversion'] == val['extraversion'].max()]\n",
    "extra_low = val.sort_values(by='extraversion')\n",
    "agree_high = val.sort_values(by='agreeableness',ascending=False)\n",
    "agree_low = val.sort_values(by='agreeableness')\n",
    "neuro_high = val[val['neuroticism'] == val['neuroticism'].max()]\n",
    "neuro_low = val.sort_values(by='neuroticism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3abb4b-a464-41ec-b597-1290c1cc758c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neuro_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a354e2-015d-4b14-8ce3-cd02f14d0aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = {\n",
    "    open_high['transcription'].to_list()[0] : open_high[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    open_low['transcription'].to_list()[1] : open_low[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    cons_high['transcription'].to_list()[0] : cons_high[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    cons_low['transcription'].to_list()[0] : cons_low[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    extra_high['transcription'].to_list()[0] : extra_high[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    extra_low['transcription'].to_list()[1] : extra_low[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    agree_high['transcription'].to_list()[1] : agree_high[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    agree_low['transcription'].to_list()[1] : agree_low[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    neuro_high['transcription'].to_list()[0] : neuro_high[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "    neuro_low['transcription'].to_list()[1] : neuro_low[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].iloc[0],\n",
    "}\n",
    "\n",
    "\n",
    "len(res), res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943c9cd-ab2e-4eff-b815-60286f95ee21",
   "metadata": {},
   "source": [
    "### Ten-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c4a93-5df4-43e3-b35b-268d6629982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import logging\n",
    "logging.disable(logging.INFO) \n",
    "logging.disable(logging.WARNING) \n",
    "\n",
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\")  # 데이터 불러오기 (First Impression V2 데이터의 Test set 불러오기)\n",
    "\n",
    "model_id = 'Bllossom/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M'  # 모델 이름\n",
    "GGUF = \"llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf\" # GGUF 경로\n",
    "model = Llama(\n",
    "    model_path='/data/visi2/llama-3-Korean-Bllossom-70B-gguf-Q4_K_M.gguf',\n",
    "    n_ctx=1024,\n",
    "    n_gpu_layers=-1       \n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "zero_shot2 = '당신은 문장에 대해 OCEAN 성격 요소 각각에 대한 점수를 알려주는 전문가 입니다. \\n\\\n",
    "OCEAN 성격 요소는 다음에 대한 사항을 확인합니다. O(Openness), C(Conscientiousness), E(Extraversion), A(Agreeableness), N(Neuroticism) \\n\\\n",
    "주어진 문장을 읽고, 문장에서 나타나는 OCEAN 성격 요소들을 분석하여 각각의 요소에 0에서 1 사이의 점수를 매기세요. \\n\\\n",
    "점수는 문장에서 해당 요소가 얼마나 잘 드러나는지를 기반으로 하며, 0에 가까울수록 전혀 드러나지 않음을, 1에 가까울수록 매우 강하게 드러남을 의미합니다. \\n\\\n",
    "다음의 예시와 같이 출력 값으로 주어진 문장에 대한 OCEAN 성격 요소 5가지를 각각의 점수로 나타내어야합니다. [O: 0.6722, C: 0.8322, E: 0.4860, A: 0.5298, N: 0.9323] \\n\\\n",
    "'\n",
    "\n",
    "ko_prompt_few_shot = zero_shot2 + '문장: \"' + few_shot_text0 + '\",\\n 결과- [O: 0.6875, C: 0.4792, E: 0.4375, A: 0.7708, N: 0.4375] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text1 + '\",\\n 결과- [O: 0.6667, C: 0.7292, E: 0.8542, A: 0.5625, N: 0.2708 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text2 + '\",\\n 결과- [O: 0.5208, C: 0.6875, E: 0.7920, A: 0.6458, N: 0.2500 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text3 + '\",\\n 결과- [O: 0.4583, C: 0.6875, E: 0.7083, A: 0.5833, N: 0.3333] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text4 + '\",\\n 결과- [O: 0.5000, C: 0.5625, E: 0.6875, A: 0.5625, N: 0.2708 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text5 + '\",\\n 결과- [O: 0.5833, C: 0.4583, E: 0.8125, A: 0.5420, N: 0.4583] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text6 + '\",\\n 결과- [O: 0.7292, C: 0.4792, E: 0.5000, A: 0.4583, N: 0.7292 ] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text7 + '\",\\n 결과- [O: 0.9792, C: 0.9792, E: 0.8333, A: 0.6458, N: 0.2083] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text8 + '\",\\n 결과- [O: 0.7920, C: 0.5625, E: 0.8542, A: 0.7083, N: 0.3750] \\n' + \\\n",
    "                    '문장: \"' + few_shot_text9 + '\",\\n 결과- [O: 0.5625, C: 0.8333, E: 0.8125, A: 0.3125, N: 0.2708] \\n'\n",
    "\n",
    "generation_kwargs = {  # Decoding/Sampling Strategy\n",
    "    \"max_tokens\" : 512, # 최대 생성 토큰, 1024\n",
    "    \"temperature\" : 0.9,\n",
    "    \"repeat_penalty\" : 1.3,\n",
    "    \"top_k\" :50,\n",
    "    \"top_p\" :0.92,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])  # 결과를 저장할 데이터프레임\n",
    "\n",
    "for content in tqdm(FI_test['transcription'].to_list()):\n",
    "    user = content\n",
    "    inputs = tokenizer.encode(zero_shot2 + '문장: \"' + user + '\",\\n 결과- [O: ', return_tensors='pt').to(\"cuda\")  # 입력 데이터 토크나이징\n",
    "    raw_inputs = zero_shot2 + '문장: \"' + user + '\",\\n 결과- [O: '  # 토크나이징 전 텍스트\n",
    "    outputs = model(raw_inputs, **generation_kwargs)\n",
    "    out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "    result_df = pd.concat([result_df, tmp_df])\n",
    "\n",
    "# KULLM, KoSOLAR (SOLAR-10.7B) : 약 21GB GPU 메모리 소모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21333f8-6e26-4810-b6a6-0ff13349dd77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['Inference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1228049-63b2-4c26-b5ee-824b8c49b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "p = re.compile('0[.]\\d*')\n",
    "\n",
    "for content in result_df['Inference'].to_list():\n",
    "    tmp = p.findall(content)\n",
    "    score.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff3022-d8a4-47c5-85d7-02125f71cf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc399d-7bfa-4ea5-b035-db28ec8431a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FI_test = pd.read_csv(\"/data/visi2/FI/KETI_test_from_ver0.4.csv\",\n",
    "                     index_col=0)\n",
    "\n",
    "FI_test['label'] = FI_test['OCEAN'].map(lambda x : [float(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46e1d8-27c8-4d5a-b5d4-5939fad0cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_arr = []\n",
    "error_idx = []\n",
    "\n",
    "for i in range(len(FI_test)):\n",
    "    try:\n",
    "        MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        error_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1857e-70a0-4c02-a5b6-7b17ae47d8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c88856-9074-4886-92c5-9437c98a5be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while len(error_idx) !=0:\n",
    "    re_df = pd.DataFrame(columns=[\"Text\", \"Inference\"])\n",
    "    \n",
    "    for data in tqdm(FI_test['transcription'][error_idx].to_list()):\n",
    "        user = data\n",
    "     #   conversation = [{'role': 'system', 'content': en_prompt}, {'role' : 'user', 'content' : 'Given Sentence: \"' + user + '\",\\n Results- [O: '}]\n",
    "        inputs = tokenizer.encode(ko_prompt_few_shot + '문장: \"' + user + '\",\\n 결과- [O: ', return_tensors='pt').to(\"cuda\")  # No template\n",
    "        outputs = model(raw_inputs, **generation_kwargs)\n",
    "\n",
    "    out_text = outputs['choices'][0]['text'][len(inputs):]\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame({'Text': [user], 'Inference': [out_text]})  # 만들어진 출력 저장하기\n",
    "    re_df = pd.concat([re_df, tmp_df])\n",
    "\n",
    "    re_score = []\n",
    "    p = re.compile('0[.]\\d*')\n",
    "    \n",
    "    for content in re_df['Inference'].to_list():\n",
    "        tmp = p.findall(content)\n",
    "        re_score.append(tmp)\n",
    "        \n",
    "    for i, idx in enumerate(error_idx):\n",
    "        score[idx] = re_score[i]\n",
    "\n",
    "    MAE_arr = []\n",
    "    error_idx = []\n",
    "    \n",
    "    for i in range(len(FI_test)):\n",
    "        try:\n",
    "            MAE_arr.append(test_compute_metrics(FI_test['label'].iloc[i][:5], score[i][:5]))\n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            error_idx.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96e10e-992f-41a4-bc8a-b8d3ebd074ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_mae = np.array(MAE_arr).mean(axis=0)\n",
    "avg_mae = np.mean(factor_mae)\n",
    "\n",
    "factor_mae, avg_mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
